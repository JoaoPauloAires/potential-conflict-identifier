# -*- coding: utf-8 -*-
import nltk
import os
import re
import random

modalVerbs = ['can', 'could', 'may', 'might', 'must', 'shall', 'should', 'will', 'would']

def cleanSent(sent):
    lSent = sent.split()
    if len(lSent) > 1:
        if lSent[1] in ['and', 'or', 'will', 'of', 'and/or']:
            return sent
    return ' '.join(lSent[1:])  

contractsDir = '/home/lsa/Dropbox/PUCRS/Dissertation/Corpus/cleantxtcorpus11/utf8'      #define the contracts' directory
sentList = file('sentList.txt', 'w')                                                   #file that will receive the contracts' sentences
noNormList = file('noNormList.txt', 'w')
normsList = file('normsList.txt', 'w')                                                 #file that receives sentences that represent norms
regExp = re.compile("(((\(([0-9]|[A-Za-z])\))|([0-9]+\.([0-9])?)) .+)")                 #regular expression to define a structure of a norm

normSents = []

sent_tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')

listContracts = os.listdir(contractsDir)                                             #get the names of files in the directory
os.chdir(contractsDir)                                                               #change the current path to the one with the contracts

allSents = []
noNormSents = []

for contract in listContracts:
    contractFile = open(contract, 'r')
    contractString = contractFile.read()
    sents = sent_tokenizer.tokenize(contractString)
    allSents = allSents + sents
    for sent in sents:
        r = regExp.findall(sent)
        if r:
            cSent = cleanSent(r[0][0])
            tokenSent = nltk.word_tokenize(cSent)
            for token in tokenSent:
                if token in modalVerbs:
                    normSents.append(cSent)
                    break
        else:
            noNormSents.append(sent)

    contractFile.close()
 
print "All: ", len(allSents), "Norm: ", len(normSents), "No Norm: ", len(noNormSents)
                

for sent in allSents:
    sentList.write(sent + "\n\n")

for sent in noNormSents:
    noNormList.write(sent + "\n\n")

for sent in normSents:
    normsList.write(sent + "\n\n")

sentList.close()
noNormList.close()
normsList.close()
