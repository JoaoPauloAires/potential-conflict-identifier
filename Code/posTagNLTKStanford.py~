#coding: utf-8
import nltk
from normClassifier import *
from nltk import *
from nltk.tag import stanford
from nltk.tag.stanford import POSTagger
jar = 'stanford-postagger.jar'
model = 'wsj-0-18-bidirectional-distsim.tagger'

stanford = POSTagger(model, jar)

result = file('data/result.txt', 'w')
sentList = open('data/trainData/sentList.txt', 'r')
sents = sentList.read();
tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')
sents = tokenizer.tokenize(sents)
classifier = start()
listResult = [];

def posTagging():
    for sent in sents:
        if classifier(feature(sent)) == "norm":
            words = nltk.word_tokenize(sent)
            posTagNLTK = nltk.pos_tag(words)
            posTagStanford = stanford.tag(words)
            NLTK_Stanford(posTagNLTK, posTagStanford)
    writeResult(sents, listResult)
    writeFile(listResult)

def writeResult(total, diff):
    result.write("Número total de normas:")
    result.write("\n");
    result.write(str(len(total)))
    result.write("\n");
    result.write("Número de diferenças encontradas:")
    result.write("\n");
    result.write(str(len(diff)));
    result.write("\n");

def writeFile(array):
    for sent in array:
         result.write("-------")
         result.write("\n");
         result.write(" ".join(word+"/"+tag for word, tag in sent))
         #result.write(sent)
         result.write("\n");
         result.write("\n");

def NLTK_Stanford(wNltk, wStanford):
    if wNltk != wStanford:
        #listResult.append("NLTK:\t");
        listResult.append(wNltk);
        #listResult.append("Stanford:\t");
        listResult.append(wStanford);

posTagging()
